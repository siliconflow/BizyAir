{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"","title":"Homepage"},{"location":"ai-assistants/introduce.html","text":"\u2601\ufe0fBizyAir SiliconCloud LLM API \u00b6 The \u2601\ufe0fBizyAir SiliconCloud LLM API node is a cloud-based AI assistant that provides a set of APIs to help you build conversational interfaces. This node offers five Large Langauge Models, including two completely free models. The default system prompt is designed to enhance the prompt setting. You also have the freedom to set other system prompts for specific tasks. \u2601\ufe0fBizyAir Image Caption \u00b6 The \u2601\ufe0fBizyAir Image Caption node is a powerful tool designed to automatically generate descriptive captions for images. It is generally very useful in the workflow of redrawing images.","title":"AI Assistant"},{"location":"ai-assistants/introduce.html#bizyair-siliconcloud-llm-api","text":"The \u2601\ufe0fBizyAir SiliconCloud LLM API node is a cloud-based AI assistant that provides a set of APIs to help you build conversational interfaces. This node offers five Large Langauge Models, including two completely free models. The default system prompt is designed to enhance the prompt setting. You also have the freedom to set other system prompts for specific tasks.","title":"\u2601\ufe0fBizyAir SiliconCloud LLM API"},{"location":"ai-assistants/introduce.html#bizyair-image-caption","text":"The \u2601\ufe0fBizyAir Image Caption node is a powerful tool designed to automatically generate descriptive captions for images. It is generally very useful in the workflow of redrawing images.","title":"\u2601\ufe0fBizyAir Image Caption"},{"location":"controlnet-preprocessor/introduce.html","text":"BizyAir ControlNet Auxiliary Preprocessors \u00b6 In the workflow of ControlNet, it is usually necessary to have image preprocessing nodes to convert images into Image Prompt that the ControlNet network can use. BizyAir offers more than 20 ControlNet preprocessing nodes. They have the following categories. Line Extractors \u00b6 \u2601\ufe0fBizyAir PiDiNet Soft-Edge Lines \u2601\ufe0fBizyAir Canny Edge \u2601\ufe0fBizyAir Binary Lines \u2601\ufe0fBizyAir Scribble Lines \u2601\ufe0fBizyAir M-LSD Lines \u2601\ufe0fBizyAir HED Soft-Edge Lines \u2601\ufe0fBizyAir Fake Scribble Lines (aka scribble_hed) \u2601\ufe0fBizyAir Realistic Lineart\" T2I-Adapter Only \u00b6 \u2601\ufe0fBizyAir Color Pallete Semantic Segmentation \u00b6 \u2601\ufe0fBizyAir UniFormer Segmentor \u2601\ufe0fBizyAir OneFormer COCO Segmentor \u2601\ufe0fBizyAir OneFormer ADE20K Segmentor \u2601\ufe0fBizyAir SAM Segmentor Normal and Depth Estimators \u00b6 \u2601\ufe0fBizyAir Zoe Depth Map \u2601\ufe0fBizyAir MiDaS Normal Map \u2601\ufe0fBizyAir MiDaS Depth Map \u2601\ufe0fBizyAir LeReS Depth Map (enable boost for leres++) \u2601\ufe0fBizyAir BAE Normal Map \u2601\ufe0fBizyAir Depth Anything V2 - Relative \u2601\ufe0fBizyAir Metric3D Depth Map \u2601\ufe0fBizyAir Metric3D Normal Map Face and Pose Estimators \u00b6 \u2601\ufe0fBizyAir OpenPose Pose \u2601\ufe0fBizyAir DWPose Estimator Tile \u00b6 \u2601\ufe0fBizyAir Tile","title":"Controlnet Preprocessing"},{"location":"controlnet-preprocessor/introduce.html#bizyair-controlnet-auxiliary-preprocessors","text":"In the workflow of ControlNet, it is usually necessary to have image preprocessing nodes to convert images into Image Prompt that the ControlNet network can use. BizyAir offers more than 20 ControlNet preprocessing nodes. They have the following categories.","title":"BizyAir ControlNet Auxiliary Preprocessors"},{"location":"controlnet-preprocessor/introduce.html#line-extractors","text":"\u2601\ufe0fBizyAir PiDiNet Soft-Edge Lines \u2601\ufe0fBizyAir Canny Edge \u2601\ufe0fBizyAir Binary Lines \u2601\ufe0fBizyAir Scribble Lines \u2601\ufe0fBizyAir M-LSD Lines \u2601\ufe0fBizyAir HED Soft-Edge Lines \u2601\ufe0fBizyAir Fake Scribble Lines (aka scribble_hed) \u2601\ufe0fBizyAir Realistic Lineart\"","title":"Line Extractors"},{"location":"controlnet-preprocessor/introduce.html#t2i-adapter-only","text":"\u2601\ufe0fBizyAir Color Pallete","title":"T2I-Adapter Only"},{"location":"controlnet-preprocessor/introduce.html#semantic-segmentation","text":"\u2601\ufe0fBizyAir UniFormer Segmentor \u2601\ufe0fBizyAir OneFormer COCO Segmentor \u2601\ufe0fBizyAir OneFormer ADE20K Segmentor \u2601\ufe0fBizyAir SAM Segmentor","title":"Semantic Segmentation"},{"location":"controlnet-preprocessor/introduce.html#normal-and-depth-estimators","text":"\u2601\ufe0fBizyAir Zoe Depth Map \u2601\ufe0fBizyAir MiDaS Normal Map \u2601\ufe0fBizyAir MiDaS Depth Map \u2601\ufe0fBizyAir LeReS Depth Map (enable boost for leres++) \u2601\ufe0fBizyAir BAE Normal Map \u2601\ufe0fBizyAir Depth Anything V2 - Relative \u2601\ufe0fBizyAir Metric3D Depth Map \u2601\ufe0fBizyAir Metric3D Normal Map","title":"Normal and Depth Estimators"},{"location":"controlnet-preprocessor/introduce.html#face-and-pose-estimators","text":"\u2601\ufe0fBizyAir OpenPose Pose \u2601\ufe0fBizyAir DWPose Estimator","title":"Face and Pose Estimators"},{"location":"controlnet-preprocessor/introduce.html#tile","text":"\u2601\ufe0fBizyAir Tile","title":"Tile"},{"location":"controlnet-union/introduce.html","text":"\u2601\ufe0fBizyAir Controlnet Union SDXL 1.0 \u00b6 \u2601\ufe0fBizyAir Controlnet Union SDXL 1.0 integrates the project controlnet-union-sdxl-1.0 . With this node, you can generate images using various control types. In conjunction with the controlnet preprocessors already provided by BizyAir, you do not need to prepare models and environments; you can directly perform tasks like image-to-image generation. Here is an example: converting a photo of a great white shark into a depth map and then drawing a cyberpunk-style submarine. You can find similar examples in the repository under the examples section. Note The complete workflow can be found at: github.com/siliconflow//BizyAir/blob/master/examples . Click the provided link above to get it. Looking forward to sharing more of your creative uses, enjoy! Parameter Explanation \u00b6 Here are 6 types of inputs, each corresponding to a specific type of ControlNet control image, and they are all of the IMAGE type. openpose_image depth_image hed_pidi_scribble_ted_image canny_lineart_anime_lineart_mlsd_image normal_image segment_image If you are unsure how to obtain such images, you can use the BizyAir ControlNet Preprocessor to generate them. You can use one or more control images simultaneously, for example, connecting both openpose_image and depth_image . However, from a practical view, it is not recommended to connect more than two control images simultaneously. prompt and negative_prompt correspond to the positive and negative prompts, respectively. A higher value for guidance_scale results in images that more closely follow the input prompt. control_guidance_start and control_guidance_end are values between 0 and 1. They indicate the proportion of the total steps during which ControlNet is applied. For example, if the total number of steps is set to 20, and control_guidance_start=0 , control_guidance_end=0.5 , only the first 10 steps will be influenced by the control image.","title":"Controlnet Union"},{"location":"controlnet-union/introduce.html#bizyair-controlnet-union-sdxl-10","text":"\u2601\ufe0fBizyAir Controlnet Union SDXL 1.0 integrates the project controlnet-union-sdxl-1.0 . With this node, you can generate images using various control types. In conjunction with the controlnet preprocessors already provided by BizyAir, you do not need to prepare models and environments; you can directly perform tasks like image-to-image generation. Here is an example: converting a photo of a great white shark into a depth map and then drawing a cyberpunk-style submarine. You can find similar examples in the repository under the examples section. Note The complete workflow can be found at: github.com/siliconflow//BizyAir/blob/master/examples . Click the provided link above to get it. Looking forward to sharing more of your creative uses, enjoy!","title":"\u2601\ufe0fBizyAir Controlnet Union SDXL 1.0"},{"location":"controlnet-union/introduce.html#parameter-explanation","text":"Here are 6 types of inputs, each corresponding to a specific type of ControlNet control image, and they are all of the IMAGE type. openpose_image depth_image hed_pidi_scribble_ted_image canny_lineart_anime_lineart_mlsd_image normal_image segment_image If you are unsure how to obtain such images, you can use the BizyAir ControlNet Preprocessor to generate them. You can use one or more control images simultaneously, for example, connecting both openpose_image and depth_image . However, from a practical view, it is not recommended to connect more than two control images simultaneously. prompt and negative_prompt correspond to the positive and negative prompts, respectively. A higher value for guidance_scale results in images that more closely follow the input prompt. control_guidance_start and control_guidance_end are values between 0 and 1. They indicate the proportion of the total steps during which ControlNet is applied. For example, if the total number of steps is set to 20, and control_guidance_start=0 , control_guidance_end=0.5 , only the first 10 steps will be influenced by the control image.","title":"Parameter Explanation"},{"location":"getting-started/installation.html","text":"Install BizyAir \u00b6 BizyAir is a set of ComfyUI nodes that allows you to skip the time-consuming process of downloading models and setting up requirements, enabling you to run ComfyUI workflows directly without being constrained by environmental limitations. You can choose any of the following methods to install BizyAir Method 1: Install via ComfyUI Manager \u00b6 Assuming your ComfyUI already has the ComfyUI Manager installed, search for BizyAir as shown in the image below. Click \"Install\" to complete the installation. Method 2: Install via git clone \u00b6 You can install BizyAir by downloading the BizyAir repository to the custom_nodes subdirectory of ComfyUI by using git clone. cd /path/to/ComfyUI/custom_nodes && \\ git clone https://github.com/siliconflow/BizyAir.git Then, restart ComfyUI. Method 3: Install via Comfy CLI \u00b6 Prerequisites Ensure pip install comfy-cli is installed. Installing ComfyUI comfy install To install the BizyAir , use the following command: comfy node install bizyair Method 4: Download windows portable ComfyUI \u00b6 For NA/EU users: https://github.com/siliconflow/ComfyUI/releases/tag/latest For CN users: https://bizy-air.oss-cn-beijing.aliyuncs.com/new_ComfyUI_windows_portable_nvidia_cu121_or_cpu.7z","title":"Installation"},{"location":"getting-started/installation.html#install-bizyair","text":"BizyAir is a set of ComfyUI nodes that allows you to skip the time-consuming process of downloading models and setting up requirements, enabling you to run ComfyUI workflows directly without being constrained by environmental limitations. You can choose any of the following methods to install BizyAir","title":"Install BizyAir"},{"location":"getting-started/installation.html#method-1-install-via-comfyui-manager","text":"Assuming your ComfyUI already has the ComfyUI Manager installed, search for BizyAir as shown in the image below. Click \"Install\" to complete the installation.","title":"Method 1: Install via ComfyUI Manager"},{"location":"getting-started/installation.html#method-2-install-via-git-clone","text":"You can install BizyAir by downloading the BizyAir repository to the custom_nodes subdirectory of ComfyUI by using git clone. cd /path/to/ComfyUI/custom_nodes && \\ git clone https://github.com/siliconflow/BizyAir.git Then, restart ComfyUI.","title":"Method 2: Install via git clone"},{"location":"getting-started/installation.html#method-3-install-via-comfy-cli","text":"Prerequisites Ensure pip install comfy-cli is installed. Installing ComfyUI comfy install To install the BizyAir , use the following command: comfy node install bizyair","title":"Method 3: Install via Comfy CLI"},{"location":"getting-started/installation.html#method-4-download-windows-portable-comfyui","text":"For NA/EU users: https://github.com/siliconflow/ComfyUI/releases/tag/latest For CN users: https://bizy-air.oss-cn-beijing.aliyuncs.com/new_ComfyUI_windows_portable_nvidia_cu121_or_cpu.7z","title":"Method 4: Download windows portable ComfyUI"},{"location":"getting-started/quick-start.html","text":"Getting Started \u00b6 1. Setting API Key \u00b6 Note You can get your API KEY from SiliconCloud for free. For the first use, you need to set your API key. Click the \"BizyAir Key\" button to launch the key setting page and set the key. Note You don't need to set the key every time you start the program. The key is cached in your local browser, and as long as you don't get a pop-up prompt asking you to enter the key, you can continue to use BizyAir Nodes. 2. Run BizyAir Examples \u00b6 Click the \"\u2601\ufe0fBizyAir Workflow Examples\" button, select the desired workflow to load, and then click the \"Queue Prompt\" button to run it. 3. More BizyAir Nodes \u00b6 All BizyAir nodes are categorized under the \"\u2601\ufe0fBizyAir\" section. You can use them with the documentation on this site.","title":"Quick Start"},{"location":"getting-started/quick-start.html#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/quick-start.html#1-setting-api-key","text":"Note You can get your API KEY from SiliconCloud for free. For the first use, you need to set your API key. Click the \"BizyAir Key\" button to launch the key setting page and set the key. Note You don't need to set the key every time you start the program. The key is cached in your local browser, and as long as you don't get a pop-up prompt asking you to enter the key, you can continue to use BizyAir Nodes.","title":"1. Setting API Key"},{"location":"getting-started/quick-start.html#2-run-bizyair-examples","text":"Click the \"\u2601\ufe0fBizyAir Workflow Examples\" button, select the desired workflow to load, and then click the \"Queue Prompt\" button to run it.","title":"2. Run BizyAir Examples"},{"location":"getting-started/quick-start.html#3-more-bizyair-nodes","text":"All BizyAir nodes are categorized under the \"\u2601\ufe0fBizyAir\" section. You can use them with the documentation on this site.","title":"3. More BizyAir Nodes"},{"location":"kolors/introduce.html","text":"Kolors \u00b6 Kolors is a large-scale text-to-image generation model based on latent diffusion, developed by the Kuaishou Kolors team. You can find more about Kolors at Kwai-Kolors/Kolors . BizyAir offers 5 nodes related to Kolors, each serving for: Kolors Sampler Text encoding VAE decoding VAE encoding Here is an example of a text-to-image workflow using Kolors: Here is an example of a image-to-image workflow using Kolors: The nodes provided by BizyAir are compatible with the nodes provided by ComfyUI-KwaiKolorsWrapper , allowing you to freely combine them. Enjoy.","title":"Kolors"},{"location":"kolors/introduce.html#kolors","text":"Kolors is a large-scale text-to-image generation model based on latent diffusion, developed by the Kuaishou Kolors team. You can find more about Kolors at Kwai-Kolors/Kolors . BizyAir offers 5 nodes related to Kolors, each serving for: Kolors Sampler Text encoding VAE decoding VAE encoding Here is an example of a text-to-image workflow using Kolors: Here is an example of a image-to-image workflow using Kolors: The nodes provided by BizyAir are compatible with the nodes provided by ComfyUI-KwaiKolorsWrapper , allowing you to freely combine them. Enjoy.","title":"Kolors"},{"location":"ksampler/introduce.html","text":"","title":"Introduce"},{"location":"others/index.html","text":"\u2601\ufe0fBizyAir Photorealistic Image Super Resolution \u00b6 This node helps you enlarge the image 4 times, suitable for non-cartoon images. \u2601\ufe0fBizyAir Anime Image Super Resolution \u00b6 This node helps you enhance the resolution of your input cartoon images. You can choose to upscale them by 2x or 4x. \u2601\ufe0fBizyAir Remove Image Background \u00b6 This node helps you remove the background, resulting in a transparent-background image. The maximum accepted image size is 1536x1536. \u2601\ufe0fBizyAir Generate Photorealistic Images \u00b6 This node can help you generate photo-style images with very simple prompts.","title":"Others"},{"location":"others/index.html#bizyair-photorealistic-image-super-resolution","text":"This node helps you enlarge the image 4 times, suitable for non-cartoon images.","title":"\u2601\ufe0fBizyAir Photorealistic Image Super Resolution"},{"location":"others/index.html#bizyair-anime-image-super-resolution","text":"This node helps you enhance the resolution of your input cartoon images. You can choose to upscale them by 2x or 4x.","title":"\u2601\ufe0fBizyAir Anime Image Super Resolution"},{"location":"others/index.html#bizyair-remove-image-background","text":"This node helps you remove the background, resulting in a transparent-background image. The maximum accepted image size is 1536x1536.","title":"\u2601\ufe0fBizyAir Remove Image Background"},{"location":"others/index.html#bizyair-generate-photorealistic-images","text":"This node can help you generate photo-style images with very simple prompts.","title":"\u2601\ufe0fBizyAir Generate Photorealistic Images"}]}